ğŸ“ TOKEN-LIMITER/
â”œâ”€ ğŸ“„ README.md
â”œâ”€ ğŸ“„ requirements.txt
â”œâ”€ ğŸ“„ .env.example
â”œâ”€ ğŸ“ data/
â”‚  â”œâ”€ ğŸ“„ checkpoints.json
â”‚  â””â”€ ğŸ“„ metadata.db
â”œâ”€ ğŸ“ src/
â”‚  â”œâ”€ ğŸ“„ app.py                 # CLI to ingest files & build vectors
â”‚  â”œâ”€ ğŸ“„ query.py               # Query interface to send retrieval-augmented prompts to ChatGPT
â”‚  â”œâ”€ ğŸ“„ splitter.py            # Chunking logic with overlap
â”‚  â”œâ”€ ğŸ“„ embedder.py            # Embedding using sentence-transformers
â”‚  â”œâ”€ ğŸ“„ store.py               # FAISS vector store + sqlite metadata + checkpointing
â”‚  â”œâ”€ ğŸ“„ retriever.py           # Retrieve top-k chunks and assemble context
â”‚  â”œâ”€ ğŸ“„ summarizer.py          # Iterative summarization to fit token budget (uses OpenAI)
â”‚  â””â”€ ğŸ“„ utils.py               # helper functions (token estimation, progress bars)
â””â”€ ğŸ“ examples/
   â”œâ”€ ğŸ“„ sample_long_text.txt
   â””â”€ ğŸ“„ run_example.sh



- Create and Activate a Virtual Environment
    Create a virtual environment: python -m venv .venv
    Activate the virtual environment:
        For Windows: .venv\Scripts\activate
        For macOS/Linux: source .venv/bin/activate
- Install Requirements
    Install all the requirements given in requirements.txt by running the command: pip install -r requirements.txt

